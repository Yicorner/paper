# 这是NIPS.PDF这篇文章的related work部分，

2.1 非生成式模型的超分辨率（Non-Generative Model-Based SR）

许多研究探讨了将 CNN 与 Transformer 架构结合，
以提升医学图像超分辨率的效果。Feng 等人 [11] 
在网络的不同阶段进行多对比度特征融合，以捕获
融合特征之间的依赖关系，从而增强其表征能力。
Zhang 等人 [58] 引入了带残差缩放的挤压与激励
（squeeze-and-excitation）注意力机制，
不仅稳定了训练过程，还实现了更精确的细纹理和
解剖结构细节重建。Li 等人 [25] 利用基于 
Transformer 的模块来促进多尺度上下文匹配，
显著提升了特征融合质量。Liang 等人 [33] 
采用混合方法，先使用 CNN 层提取浅层特征，
再通过 Swin Transformer 模块进行层级建模，
以实现更有效的全局特征聚合和细粒度细节重建。
此外，Lei 等人 [24] 观察到多对比度 MR 图像
在结构信息（如解剖结构与边缘）上具有一致性，
但在对比度上存在差异。基于这一观察，他们提出
了一种分解式变分网络，用于解耦并重建共享与模
态特定的成分。Georgescu 等人 [15] 设计了多
头空间注意力机制，其中每个注意力头具有不同的
感受野，以捕获不同尺度的空间信息。尽管这些方
法在生成速度和稳定性方面表现良好，但在细节丰
富度上仍弱于生成式模型，难以刻画复杂纹理与细微解剖差异。

2.2 基于生成式模型的超分辨率（Generative Model-Based SR）

扩散模型（DMs）[17] 作为一类概率生成模型，通过随机迭代去噪过程从高斯噪声中合成数据样本。在医学图像超分辨率中，尤其是在 MRI 中，DMs 展现出巨大潜力。Li 等人 [29] 提出了首个基于扩散模型的单图像超分辨率框架，并取得了有前景的结果。Mao 等人 [38] 构建了一个用于多对比度 MRI 的条件扩散模型，实现了结构化的图像超分辨率。Chung 等人 [5] 通过在反向扩散过程中初始化单次前向推理，减少了所需的采样步骤，从而降低了计算成本。此外，Chung 等人 [6] 提出了用于加速 MRI 重建的基于 score 的扩散模型。Gao 等人 [13] 提出了一种隐式扩散模型，将潜在扩散 [44] 与条件强化机制相结合，以实现高保真与连续性的图像超分辨率。最近，Li 等人 [27] 引入了用于加速去噪步骤的扩散先验模型，并将其整合到一个基于 Transformer 的多对比度超分辨率框架中，从而实现高效的 MRI 图像生成。

2.3 视觉自回归模型（Visual Autoregressive Models）

视觉自回归模型通常采用类似 VQ-VAE 的框架 [47]，将图像转化为离散序列，从而实现下一 token 预测以用于图像生成 [23,45,49,16]。然而，该方法破坏了二维图像的固有空间结构，且通常生成较慢。为解决这一效率问题，Chang 等人 [3] 提出了迭代的掩码 token 预测模型，大幅加速了图像生成过程。但这些技术仍难以完全保持图像的空间连续性与结构完整性。为突破这一限制 Fan 等人 [46] 提出了从下一 token 预测到下一尺度预测的生成范式转变。该层级式生成策略在保持高可扩展性的同时，显著提升了图像的真实性。在此基础上，基于视觉自回归的模型（VAR-based models）在多种生成任务中表现出色，包括文本生成图像 [56]、图像生成图像 [54,32]、图像修复 [48] 以及图像超分辨率 [42] 等。
